{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Handwritten Digits with VAEs in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "y_data = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=x_data, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=y_data, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x, h1, h2, z):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(x, h1)\n",
    "        self.l2 = nn.Linear(h1, h2)\n",
    "        self.l31 = nn.Linear(h2, z)\n",
    "        self.l32 = nn.Linear(h2, z)\n",
    "        \n",
    "        self.l4 = nn.Linear(z, h2)\n",
    "        self.l5 = nn.Linear(h2, h1)\n",
    "        self.l6 = nn.Linear(h1, x)\n",
    "    \n",
    "    def encoder(self, x_in):\n",
    "        h = F.relu(self.l1(x_in))\n",
    "        h = F.relu(self.l2(h))\n",
    "        return self.l31(h), self.l32(h)\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.l4(z))\n",
    "        h = F.relu(self.l5(h))\n",
    "        return torch.sigmoid(self.l6(h))\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return torch.add(eps.mul(std), mu)\n",
    "    \n",
    "    def forward(self, x_in):\n",
    "        mu, log_var = self.encoder(x_in.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (l1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (l2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (l31): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (l32): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (l4): Linear(in_features=2, out_features=256, bias=True)\n",
       "  (l5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (l6): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(x=784, h1= 512, h2=256, z=2)\n",
    "    \n",
    "vae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 512]         401,920\n",
      "            Linear-2                  [-1, 256]         131,328\n",
      "            Linear-3                    [-1, 2]             514\n",
      "            Linear-4                    [-1, 2]             514\n",
      "            Linear-5                  [-1, 256]             768\n",
      "            Linear-6                  [-1, 512]         131,584\n",
      "            Linear-7                  [-1, 784]         402,192\n",
      "================================================================\n",
      "Total params: 1,068,820\n",
      "Trainable params: 1,068,820\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 4.08\n",
      "Estimated Total Size (MB): 4.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vae, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters())\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()) # KL Divergence from MIT 6.S191\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        r_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(r_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoch: {} Train mean loss: {:.8f}'.format(epoch, train_loss / len(train_loader.dataset)), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    vae.eval()\n",
    "    test_loss=0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.to(device)\n",
    "            r, mu, log_var = vae(data)\n",
    "            test_loss += loss_function(r, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Epoch: {} Test mean loss: {:.8f}'.format(epoch, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train mean loss: 178.41738145 Epoch: 1 Test mean loss: 162.53292871\n",
      "Epoch: 2 Train mean loss: 157.97955275 Epoch: 2 Test mean loss: 154.79316367\n",
      "Epoch: 3 Train mean loss: 152.61461733 Epoch: 3 Test mean loss: 151.00139668\n",
      "Epoch: 4 Train mean loss: 149.27334487 Epoch: 4 Test mean loss: 148.64444863\n",
      "Epoch: 5 Train mean loss: 147.17804229 Epoch: 5 Test mean loss: 146.64882686\n",
      "Epoch: 6 Train mean loss: 145.73971899 Epoch: 6 Test mean loss: 145.84128945\n",
      "Epoch: 7 Train mean loss: 144.52863384 Epoch: 7 Test mean loss: 144.99415273\n",
      "Epoch: 8 Train mean loss: 143.56036440 Epoch: 8 Test mean loss: 144.05461689\n",
      "Epoch: 9 Train mean loss: 142.85794180 Epoch: 9 Test mean loss: 143.67806162\n",
      "Epoch: 10 Train mean loss: 142.33500907 Epoch: 10 Test mean loss: 143.24529170\n",
      "Epoch: 11 Train mean loss: 141.67030042 Epoch: 11 Test mean loss: 142.41908887\n",
      "Epoch: 12 Train mean loss: 141.20681271 Epoch: 12 Test mean loss: 142.28842197\n",
      "Epoch: 13 Train mean loss: 140.65099388 Epoch: 13 Test mean loss: 142.05468740\n",
      "Epoch: 14 Train mean loss: 140.31201825 Epoch: 14 Test mean loss: 141.49871523\n",
      "Epoch: 15 Train mean loss: 139.98899539 Epoch: 15 Test mean loss: 141.57866992\n",
      "Epoch: 16 Train mean loss: 139.47371263 Epoch: 16 Test mean loss: 141.04912969\n",
      "Epoch: 17 Train mean loss: 139.27611641 Epoch: 17 Test mean loss: 140.63293027\n",
      "Epoch: 18 Train mean loss: 138.94549971 Epoch: 18 Test mean loss: 140.13365811\n",
      "Epoch: 19 Train mean loss: 138.66373198 Epoch: 19 Test mean loss: 140.37941484\n",
      "Epoch: 20 Train mean loss: 138.35537284 Epoch: 20 Test mean loss: 140.52576582\n",
      "Epoch: 21 Train mean loss: 138.05536408 Epoch: 21 Test mean loss: 139.82785234\n",
      "Epoch: 22 Train mean loss: 137.86075579 Epoch: 22 Test mean loss: 139.40900771\n",
      "Epoch: 23 Train mean loss: 137.60739660 Epoch: 23 Test mean loss: 139.41344766\n",
      "Epoch: 24 Train mean loss: 137.47576730 Epoch: 24 Test mean loss: 139.55546328\n",
      "Epoch: 25 Train mean loss: 137.45908408 Epoch: 25 Test mean loss: 139.34639199\n",
      "Epoch: 26 Train mean loss: 137.18282168 Epoch: 26 Test mean loss: 139.66374150\n",
      "Epoch: 27 Train mean loss: 137.47926159 Epoch: 27 Test mean loss: 139.13800264\n",
      "Epoch: 28 Train mean loss: 136.97931600 Epoch: 28 Test mean loss: 138.85996084\n",
      "Epoch: 29 Train mean loss: 136.66430540 Epoch: 29 Test mean loss: 138.53840225\n",
      "Epoch: 30 Train mean loss: 136.60734557 Epoch: 30 Test mean loss: 138.63714570\n",
      "Epoch: 31 Train mean loss: 136.38743338 Epoch: 31 Test mean loss: 138.83892607\n",
      "Epoch: 32 Train mean loss: 136.19310827 Epoch: 32 Test mean loss: 138.61381611\n",
      "Epoch: 33 Train mean loss: 136.22701950 Epoch: 33 Test mean loss: 138.66890703\n",
      "Epoch: 34 Train mean loss: 136.06704442 Epoch: 34 Test mean loss: 138.44839355\n",
      "Epoch: 35 Train mean loss: 135.70656136 Epoch: 35 Test mean loss: 138.29142529\n",
      "Epoch: 36 Train mean loss: 135.65310775 Epoch: 36 Test mean loss: 138.18411035\n",
      "Epoch: 37 Train mean loss: 135.52927080 Epoch: 37 Test mean loss: 138.86730859\n",
      "Epoch: 38 Train mean loss: 135.61199054 Epoch: 38 Test mean loss: 138.59232275\n",
      "Epoch: 39 Train mean loss: 135.48665114 Epoch: 39 Test mean loss: 138.18853711\n",
      "Epoch: 40 Train mean loss: 135.35390374 Epoch: 40 Test mean loss: 138.38245439\n",
      "Epoch: 41 Train mean loss: 135.47773488 Epoch: 41 Test mean loss: 138.41789824\n",
      "Epoch: 42 Train mean loss: 135.47624535 Epoch: 42 Test mean loss: 138.51927344\n",
      "Epoch: 43 Train mean loss: 135.27219660 Epoch: 43 Test mean loss: 137.89624229\n",
      "Epoch: 44 Train mean loss: 134.95724870 Epoch: 44 Test mean loss: 138.12449961\n",
      "Epoch: 45 Train mean loss: 135.07219764 Epoch: 45 Test mean loss: 138.10119395\n",
      "Epoch: 46 Train mean loss: 134.95942077 Epoch: 46 Test mean loss: 137.63560869\n",
      "Epoch: 47 Train mean loss: 135.02883356 Epoch: 47 Test mean loss: 138.05228203\n",
      "Epoch: 48 Train mean loss: 134.67912178 Epoch: 48 Test mean loss: 137.81978223\n",
      "Epoch: 49 Train mean loss: 134.56565835 Epoch: 49 Test mean loss: 138.04519795\n",
      "Epoch: 50 Train mean loss: 134.81715055 Epoch: 50 Test mean loss: 138.01718242\n"
     ]
    }
   ],
   "source": [
    "n_epoches = 50\n",
    "\n",
    "for epoch in range(1, n_epoches+1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(1, 2).to(device)\n",
    "    for i in range(100):\n",
    "        z = torch.add(z, 0.05)\n",
    "        \n",
    "        sample = vae.decoder(z).to(device)\n",
    "        save_image(sample.view(1, 28, 28), './samples/sample' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
